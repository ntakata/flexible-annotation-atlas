{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide internal ROIs that have voxel counts\n",
    "This notebook divides ROIs in an anatomical ontology (AO) text-file if these are internal nodes with voxel counts (VC) > 0 in an annotation volume (AV). A divided ROI has a name and acronym suffixed with \"peripheral\" such as \"original name_peripheral\" and \"original acronym_peri\". ID of divided ROI is newly assigned (>= 10^9).\n",
    "\n",
    "- input\n",
    "    - 1_VC_pruned.json\n",
    "- outputs\n",
    "    - 1_VC_pruned_divided.json\n",
    "    - dividedIDs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = 'data'\n",
    "fn_input_AO = '1_VC_pruned.json'\n",
    "fn_output_AO = '1_VC_pruned_divided.json'\n",
    "fn_output_ID = 'dividedIDs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "from jsonpath_rw import jsonpath, parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_data, fn_input_AO)) as f:\n",
    "    df_AO_VC_pruned = json.load(f, object_pairs_hook=OrderedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ID-acronym to prepare candidate ID for divided ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath_expr = parse('$..id')\n",
    "\n",
    "IDacronym_list = [[match.value, \\\n",
    "                  eval(\"df_AO_VC_pruned['msg'][0]\" +str(match.full_path).\\\n",
    "                      replace('.','').replace('children',\"['children']\").\\\n",
    "                      replace('id',\"\") + \"['acronym']\"),\\\n",
    "                  eval(\"df_AO_VC_pruned['msg'][0]\" +str(match.full_path).\\\n",
    "                      replace('.','').replace('children',\"['children']\").\\\n",
    "                      replace('id',\"\") + \"['name']\")]\n",
    "                 for match in jsonpath_expr.find(df_AO_VC_pruned['msg'][0])]\n",
    "IDacronym = pd.DataFrame(IDacronym_list, columns=['ID', 'acronym', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614454277\n"
     ]
    }
   ],
   "source": [
    "maxID = IDacronym['ID'].max() # 614454277 in the original annotation ontology file\n",
    "print(maxID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if maxID < 10**9:\n",
    "    CandidateID = 10**9 -1 # -1 to start from 10**9, not \"10**9 + 1\"\n",
    "else:\n",
    "    CandidateID = maxID + 1\n",
    "CandidateID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide internal nodes with voxel counts > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Divide_internal_ROI_with_VC_in_AO(match_id, match_fullpath):\n",
    "    if match_id == 0: return # Children is not defined for a root node.\n",
    "    # id_offset = 10**9 # ID of divided node = original ID + this offset\n",
    "    global df_AO_VC_pruned_leafed\n",
    "    global CandidateID\n",
    "    bool1 = eval((\"df_AO_VC_pruned_leafed\"+\\\n",
    "                str(match_fullpath).replace('.','')\\\n",
    "                .replace('msg', \"['msg']\")\\\n",
    "                .replace('children', \"['children']\")\\\n",
    "                .replace('id','')+\"['children'] != []\")) # true if non-leaf node\n",
    "    bool2 = eval((\"df_AO_VC_pruned_leafed\"+\\\n",
    "                str(match_fullpath).replace('.','')\\\n",
    "                .replace('msg', \"['msg']\")\\\n",
    "                .replace('children', \"['children']\")\\\n",
    "                .replace('id','')+\"['voxel_count'] is not None\")) # true if voxel_count > 0\n",
    "    if bool1 and bool2:\n",
    "        CandidateID += 1 \n",
    "        source_acronym =  eval(\"df_AO_VC_pruned_leafed\"+\\\n",
    "                str(match_fullpath).replace('.','')\\\n",
    "                .replace('msg', \"['msg']\").replace('children', \"['children']\")\\\n",
    "                .replace('id', \"['acronym']\")) # acronym for matched ID\n",
    "        source_name =  eval(\"df_AO_VC_pruned_leafed\"+\\\n",
    "                str(match_fullpath).replace('.','')\\\n",
    "                .replace('msg', \"['msg']\").replace('children', \"['children']\")\\\n",
    "                .replace('id', \"['name']\")) # name for matched ID\n",
    "        source_original_content =  eval(\"copy.deepcopy(df_AO_VC_pruned_leafed\"+\\\n",
    "                str(match_fullpath).replace('.','')\\\n",
    "                .replace('msg', \"['msg']\")\\\n",
    "                .replace('children', \"['children']\").replace('id', \"\")+\")\") # OrderedDict\n",
    "        source_child_index = int(str(match_fullpath)\\\n",
    "            [str(match_fullpath).rfind(\"[\")+1:str(match_fullpath).rfind(\"]\")])\n",
    "        source_parent_path = \"df_AO_VC_pruned_leafed\"+str(match_fullpath)\\\n",
    "            [0:str(match_fullpath).rfind(\"[\")-1].replace('.','')\\\n",
    "            .replace('msg', \"['msg']\")\\\n",
    "            .replace('children', \"['children']\") # ./children[x]â†’./children\n",
    "        source_original_voxelcount = eval((\"df_AO_VC_pruned_leafed\"+\\\n",
    "                str(match_fullpath).replace('.','').replace('msg', \"['msg']\")\\\n",
    "                .replace('children', \"['children']\").replace('id','')+\"['voxel_count']\"))\n",
    "        exec(source_parent_path + \"[\" +str(source_child_index) +\"]['voxel_count'] = None\")\n",
    "        exec(source_parent_path+\\\n",
    "                \".insert(\" + str(source_child_index + 1) + \", source_original_content)\") \n",
    "        exec(source_parent_path + \"[\" + str(source_child_index + 1) + \"]['acronym'] = '\"\\\n",
    "             + source_acronym + \"_peri'\")\n",
    "        exec(source_parent_path + \"[\" + str(source_child_index + 1) + \"]['name'] = '\"\\\n",
    "             + source_name + \"_peripheral'\")\n",
    "        exec(source_parent_path + \"[\" + str(source_child_index + 1) + \"]['children'] = None\")\n",
    "        exec(source_parent_path + \"[\" + str(source_child_index + 1) + \"]['id'] = \"\\\n",
    "             + str(CandidateID))\n",
    "        exec(source_parent_path + \"[\" + str(source_child_index + 1) +\\\n",
    "             \"]['voxel_count'] = \" + str(source_original_voxelcount))\n",
    "        return [match_id, source_acronym, source_name, source_original_voxelcount, CandidateID] # Leafed ID and its acronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath_expr = parse('$..id')\n",
    "df_AO_VC_pruned_leafed = copy.deepcopy(df_AO_VC_pruned)\n",
    "ID_divided = []\n",
    "ID_divided = [Divide_internal_ROI_with_VC_in_AO(match.value, match.full_path)\\\n",
    "            for match in reversed(jsonpath_expr.find(df_AO_VC_pruned_leafed))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get internal ROIs with voxel size > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_divided_wo_None = []\n",
    "ID_divided_wo_None = [x for x in ID_divided if x is not None]\n",
    "df_dividedIDs = pd.DataFrame(ID_divided_wo_None, columns=['divided_ID', 'acronym', 'name', 'voxel_count', 'new_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save AO and csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AO json-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_data, fn_output_AO), mode='w') as fw:\n",
    "    json.dump(df_AO_VC_pruned_leafed, fw, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv file with divided IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dividedIDs.to_csv(os.path.join(dir_data, fn_output_ID), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>divided_ID</th>\n",
       "      <th>acronym</th>\n",
       "      <th>name</th>\n",
       "      <th>voxel_count</th>\n",
       "      <th>new_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>V4</td>\n",
       "      <td>fourth ventricle</td>\n",
       "      <td>523</td>\n",
       "      <td>1000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>VL</td>\n",
       "      <td>lateral ventricle</td>\n",
       "      <td>2138</td>\n",
       "      <td>1000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>st</td>\n",
       "      <td>stria terminalis</td>\n",
       "      <td>292</td>\n",
       "      <td>1000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>863</td>\n",
       "      <td>rust</td>\n",
       "      <td>rubrospinal tract</td>\n",
       "      <td>564</td>\n",
       "      <td>1000000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>784</td>\n",
       "      <td>cst</td>\n",
       "      <td>corticospinal tract</td>\n",
       "      <td>92</td>\n",
       "      <td>1000000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   divided_ID acronym                 name  voxel_count      new_ID\n",
       "0         145      V4     fourth ventricle          523  1000000000\n",
       "1          81      VL    lateral ventricle         2138  1000000001\n",
       "2         301      st     stria terminalis          292  1000000002\n",
       "3         863    rust    rubrospinal tract          564  1000000003\n",
       "4         784     cst  corticospinal tract           92  1000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dividedIDs.head() # .shape (29, 3) There were 29 inner nodes with voxel counts > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614454277"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDacronym['ID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614454277\n",
      "8.788489571542424\n",
      "9.632959861247398\n",
      "4.294375337334885\n"
     ]
    }
   ],
   "source": [
    "# import math\n",
    "# print(IDacronym['ID'].max())\n",
    "# print(math.log10(IDacronym['ID'].max()))\n",
    "# print(math.log10(2**32))\n",
    "# print(10**0.6329)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "946px",
    "left": "0px",
    "top": "92px",
    "width": "336.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
